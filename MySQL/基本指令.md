#### 表操作
```mysql
-- 查看所有数据库
SHOW DATABASES;
-- 创建数据库
CREATE DATABASE db_name CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;
-- 选择数据库
USE db_name;
-- 查看当前使用的数据库
SELECT DATABASE();
-- 删除数据库
DROP DATABASE db_name;
-- 查看所有表
SHOW TABLES;
-- 查看表结构
DESC table_name;
DESCRIBE table_name;
SHOW COLUMNS FROM table_name;
-- 删除表
DROP TABLE table_name;
-- 重命名表
RENAME TABLE old_name TO new_name;
-- 表添加新字段
alter table emp add nickname varchar(20) comment '昵称';
-- 查看表结构
desc emp;
```

#### 创建表，显示表，查看表结构
![[Pasted image 20250409194858.png]]
#### 数据操作
```MySQL
-- 插入数据
INSERT INTO users (username, email) VALUES ('john', 'john@example.com');

-- 批量插入
INSERT INTO users (username, email) VALUES 
('alice', 'alice@example.com'),
('bob', 'bob@example.com');

-- 查询数据
SELECT * FROM users;
SELECT username, email FROM users WHERE id = 1;

-- 更新数据
UPDATE users SET email = 'new@example.com' WHERE id = 1;

-- 删除数据
DELETE FROM users WHERE id = 1;
```
![[Pasted image 20250410120836.png]]
在谈隔离级别之前，你首先要知道，你隔离得越严实，效率就会越低。因此很多时候，我们都要 在二者之间寻找一个平衡点。SQL标准的事务隔离级别包括:读未提交(read uncommitted)、 读提交(read committed)、可重复读(repeatable read)和串行化(serializable )。下面我逐 一为你解释:
<mark style="background: #BBFABBA6;">读未提交</mark>是指，一个事务还没提交时，它做的变更就能被别的事务看到。
<mark style="background: #BBFABBA6;">读提交</mark>是指，一个事务提交之后，它做的变更才会被其他事务看到。 
<mark style="background: #BBFABBA6;">可重复读</mark>是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一 致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。
<mark style="background: #BBFABBA6;">串行化</mark>，顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突 的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。


#### 联结表
##### 内部联结
```sql
SELECT 
    c.customer_id,
    c.customer_name,
    o.order_id,
    o.order_date,
    o.amount
FROM 
    customers c,
    orders o
WHERE 
    c.customer_id = o.customer_id;
```
![[Pasted image 20250417185130.png]]


#### 视图
```MySQL
CREATE VIEW shitu AS  
SELECT Concat(RTRIM(id),'(',age,')')  
    AS title  
FROM emp  
ORDER BY id;  
  
SELECT * FROM shitu;
```

#### 函数
```mysql
CREATE PROCEDURE itheima.moneytotal(  
    IN  id  INT,  
    IN taxable    BOOLEAN,  
    OUT ototal DECIMAL(8,2) -- 8 表示总位数（整数 + 小数部分），2 表示小数位数。  
)COMMENT 'Obtain order total ,optionally adding tax'  
BEGIN  
    DECLARE total DECIMAL(8,2);  
    DECLARE taxrate INT DEFAULT 6; -- 声明一个名为 taxrate 的局部变量，类型为 INT（整数），并设置默认值为 6  
    SELECT Sum(price*days)  
        FROM emp  
            WHERE emp.id=id  
    INTO total;  
  
    IF taxable THEN  
        SELECT total+(total/100*taxrate) INTO total;  
    end if;  
  
    SELECT total INTO ototal;  
END;

-- 调用
CALL itheima.ordertotal(1, TRUE, @total);  -- TRUE表示要加税  
SELECT @total AS '订单总金额';
```



#### 日志模块
<mark style="background: #BBFABBA6;">MySQL构造</mark>
![[1748523808785_d.png]]



与查询流程不一样的是，更新流程还涉及两个重要的日志模块，它们正是我们今天要讨论的主 角:<mark style="background: #BBFABBA6;">redo log</mark>(重做日志)和 <mark style="background: #BBFABBA6;">binlog</mark>(归档日志)

<mark style="background: #BBFABBA6;">redo log 引擎层</mark>
redolog是物理日志，记录的是“在某个数据页上做了什么修改”
当有一条记录需要更新的时候，InnoDB引擎就会先把记录写到redo log(粉板)里 面，并更新内存，这个时候更新就算完成了。同时，InnoDB引擎会在适当的时候，将这个操作 记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做，这就像打烊以后掌柜做的 事。
如果今天赊账的不多，掌柜可以等打烊后再整理。但如果某天赊账的特别多，粉板写满了，又怎 么办呢?这个时候掌柜只好放下手中的活儿，把粉板中的一部分赊账记录更新到账本中，然后把 这些记录从粉板上擦掉，为记新账腾出空间。
与此类似，InnoDB的redo log是固定大小的，比如可以配置为一组4个文件，每个文件的大小是 1GB，那么这块“粉板”总共就可以记录4GB的操作。
redolog是循环写的，空间固定会用完;
<mark style="background: #FFF3A3A6;">就算MySQL服务失效了，redo log 仍然存在</mark>

<mark style="background: #BBFABBA6;">binlog 归档日志</mark>
是Server层实现的，所有引擎都能用，
binlog是逻辑日志，记录的是这个语句的原始逻辑，比如“给ID=2这一行的c字段加1 ”。
binlog是可以追加写入的。“追加写”是指binlog文件
写到一定大小后会切换到下一个，并不会覆盖以前的日志。

<mark style="background: #BBFABBA6;">更新写入日志过程：</mark>
1. <mark style="background: #BBFABBA6;">执行器</mark>先找引擎取ID=2这一行，引擎使用树搜索找到这一行。如果这一行所在数据页在内存中，直接返回给执行器，否则从磁盘中读入内存，然后再返回。
2. <mark style="background: #BBFABBA6;">执行器</mark>拿到行数据，把这个值加一，得到新数据，调用引擎接口写入这新数据
3. <mark style="background: #BBFABBA6;">引擎</mark>将这行新数据更新到内存中，同时把这个更新操作记录到redo log中，状态标为 prepare，告知执行器随时可以提交事务。
4. <mark style="background: #BBFABBA6;">执行器</mark>生成这个操作的binlog,把binlog写入磁盘
5. <mark style="background: #BBFABBA6;">执行器</mark>调用引擎提交事务的接口，把redo log 改为commit状态，更新完成。
![[1748529750593_d.png]]
#### 事务隔离
事务支持在引擎层实现  数据库里面会创建一个视图，访问的时候以视图的逻辑为准
<mark style="background: #BBFABBA6;">读未提交是指</mark>，一个事务还没提交时，它做的变更就能被别的事务看到。
没有视图概念
<mark style="background: #BBFABBA6;">读提交</mark> 是指，一个事务提交之后，它做的变更才会被其他事务看到。 


<mark style="background: #FFB8EBA6;">可重复读是默认级别</mark>
<mark style="background: #BBFABBA6;">可重复读</mark>是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一 致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。 
这个视图是事务启动时创建的，整个事务存在期间都会用
<mark style="background: #BBFABBA6;">串行化</mark>，顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突 的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。
其中“读提交”和“可重复读”比较难理解，所以我用一个例子说明这几种隔离级别。假设数据表T中 只有一列，其中一行的值为1，下面是按照时间顺序执行两个事务的行为。


<mark style="background: #BBFABBA6;">避免长事务的影响</mark>
启动事务方法：
1.  set autocommit=1,  显式启动事务语句，set autocommit=1,   自动提交模式，每条语句 begin 或 start transaction。配套的提交语句是commit，回滚语句是 rollback。
     可以使用commit work and chain,提交事务并自动启动下一个事务
3. set autocommit=0，这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个 select语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行 commit 或 rollback 语句，或者断开连接。
可以在information_schema库的innodb_trx这个表中查询长事务，比如下面这个语句，用于查 找持续时间超过60s的事务。
```sql
select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))>60
```
#### 索引
如果语句是select * from T where ID=500，即<mark style="background: #BBFABBA6;">主键查询</mark>方式，则只需要搜索ID这棵B+树; 如果语句是select * from T where k=5，即普通索引查询方式，则需要先搜索k索引树，得到ID 的值为500，再到ID索引树搜索一次。这个过程称为回表。
也就是说，<mark style="background: #BBFABBA6;">基于非主键索引</mark>的查询需要多扫描一棵索引树。因此，我们在应用中应该<mark style="background: #BBFABBA6;">尽量使用主键查询。</mark>
主键也可以使用多个字段。

<mark style="background: #BBFABBA6;">自增主键</mark>是指自增列上定义的主键，在建表语句中一般是这么定义的: NOT NULL PRIMARY KEY AUTO_INCREMENT。
插入新记录的时候可以不指定ID的值，系统会获取当前ID最大值加1作为下一条记录的ID值。 也就是说，自增主键的插入数据模式，正符合了我们前面提到的递增插入的场景。每次插入一条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂。

<mark style="background: #BBFABBA6;">业务逻辑的字段做主键</mark>，往往不容易保证有序插入，写数据成本较高
主键长度越小，普通索引的叶子节点就越小，普通索引所占的空间也越小。
如果键稳定，不经常变化，最好唯一，最好键很短

![[1748580289586_d.png]]
```sql title:创建联合索引
CREATE INDEX idx_name_age ON users(last_name, first_name, age);
```
联合索引是有序的
#### 全局锁和表锁
<mark style="background: #BBFABBA6;">全局锁</mark>，对整个数据库实例加锁，整个库出于只读状态，做数据备份时使用。
既然要全库只读，为什么不<mark style="background: #BBFABBA6;">1、使用set global readonly=true</mark>的方式呢?确实 readonly方式也可以让全库进入只读状态，但我还是会建议你用<mark style="background: #BBFABBA6;">2、FTWRL方式</mark>，主要有两个原因:
一是，在有些系统中，readonly的值会被用来做其他逻辑，比如用来判断一个库是主库还是备 库。因此，修改global变量的方式影响面更大，我不建议你使用。 二是，在异常处理机制上有差异。如果执行FTWRL命令之后由于客户端发生异常断开，那么 MySQL会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为 readonly之后，如果客户端发生异常，则数据库就会一直保持readonly状态，这样会导致整个 库长时间处于不可写状态，风险较高。
官方自带的<mark style="background: #BBFABBA6;">3、逻辑备份工具是mysqldump</mark>。当mysqldump使用参数–single-transaction的时候，导 数据之前就会启动一个事务，来确保拿到一致性视图。而由于MVCC的支持，这个过程中数据是 可以正常更新的。
你一定在疑惑，有了这个功能，为什么还需要FTWRL呢?一致性读是好，但前提是引擎要支 持这个隔离级别。比如，对于MyISAM这种不支持事务的引擎，如果备份过程中有更新，总是 只能取到最新的数据，那么就破坏了备份的一致性。这时，我们就需要使用FTWRL命令了。
<mark style="background: #BBFABBA6;">表级锁
</mark>
表锁的语法是<mark style="background: #BBFABBA6;"> lock tables ...read/write</mark>。与FTWRL类似，可以用unlock tables主动释放锁， 也可以在客户端断开的时候自动释放。需要注意，lock tables语法除了会限制别的线程的读写 外，也限定了本线程接下来的操作对象。
举个例子, 如果在某个线程A中执行lock tables t1 read, t2 write; 这个语句，则其他线程写t1、读 写t2的语句都会被阻塞。同时，线程A在执行unlock tables之前，也只能执行读t1、读写t2的操 作。连写t1都不允许，自然也不能访问其他表。
![[Pasted image 20250530174256.png]]
另一类表级的锁是MDL(metadata lock)。<mark style="background: #BBFABBA6;">MDL</mark>不需要显式使用，在访问一个表的时候会被 自动加上。MDL的作用是，保证读写的正确性。你可以想象一下，如果一个查询正在遍历一个 表中的数据，而执行期间另一个线程对这个表结构做变更，删了一列，那么查询线程拿到的结果 跟表结构对不上，肯定是不行的。
因此，在MySQL 5.5版本中引入了MDL，当对一个表做增删改查操作的时候，加MDL读锁;当 要对表做结构变更操作的时候，加MDL写锁。
读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。
读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线 程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。

<mark style="background: #BBFABBA6;">更改表结构</mark>
<mark style="background: #BBFABBA6;">事务中的MDL锁，在语句执行开始时申请，但是语句结束后并不会马上释 放，而会等到整个事务提交后再释放。</mark>
![[1748598774204_d.png]]
如果只有session C自己被阻塞还没什么关系，但是之后所有要在表t上新申请MDL读锁的请求也 会被session C阻塞。前面我们说了，所有对表的增删改查操作都需要先申请MDL读锁，就都被 锁住，等于这个表现在完全不可读写了。
<mark style="background: #BBFABBA6;">如何安全地给小表加字段?</mark>
首先我们要解决长事务，事务不提交，就会一直占着MDL锁。在MySQL的information_schema 库的 innodb_trx表中，你可以查到当前执行中的事务。如果你要做DDL变更的表刚好有长事务 在执行，要考虑先暂停DDL，或者kill掉这个长事务。
<mark style="background: #BBFABBA6;">如果你要变更的表是一个热点表，虽然数据量不大，但是上面的请求很频 繁，而你不得不加个字段，你该怎么做呢?</mark>
```sql
ALTER TABLE tbl_name NOWAIT add column 
ALTER TABLE tbl_name WAIT N add column   
```
`NOWAIT`
- 尝试立即获取表上的元数据锁(MDL)
    
- 如果无法立即获得锁（表正在被其他会话使用），则**立即失败**并报错
    
- 不会排队等待锁释放
`WAIT N`
- 尝试获取元数据锁时，最多等待 N 秒
    
- 在等待期间如果获得锁，则继续执行DDL
    
- 超过N秒仍未获得锁则**放弃操作**并报错

#### 行锁
![[1748600626573_d.png]]
实际上事务B的update语句会被阻塞，直到事务A执行commit之后，事务B才 能继续执行。
知道了这个答案，你一定知道了事务A持有的两个记录的行锁，都是在commit的时候才释放的。 也就是说，在InnoDB事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。

<mark style="background: #BBFABBA6;">如果你的事务中需要锁多个行，要把 最可能造成锁冲突、最可能影响并发度的锁尽量往后放。我给你举个例子。</mark>
假设你负责实现一个电影票在线交易业务，顾客A要在影院B购买电影票。我们简化一点，这个 业务需要涉及到以下操作:
1. 从顾客A账户余额中扣除电影票价;
2. 给影院B的账户余额增加这张电影票价; 3. 记录一条交易日志。
所有的操作需要的行锁都是在事务提交的时候才 释放的。所以，如果你把语句2安排在最后，比如按照<mark style="background: #BBFABBA6;">3、1、2</mark>这样的顺序，那么影院账户余额 这一行的锁时间就最少。这就最大程度地减少了事务之间的锁等待，提升了并发度。
好了，现在由于你的正确设计，影院余额这一行的行锁在一个事务中不会停留很长时间。但是， 这并没有完全解决你的困扰。
如果这个影院做活动，可以低价预售一年内所有的电影票，而且这个活动只做一天。于是在活动 时间开始的时候，你的MySQL就挂了。你登上服务器一看，CPU消耗接近100%，但整个数据库 每秒就执行不到100个事务。
<mark style="background: #BBFABBA6;">死锁</mark>
![[1748601710608_d.png]]
事务A与B互相等待对方资源释放
方法一：直接进入等待，直到超时，这个超时时间可以通过参数 innodb_lock_wait_timeout来设置。默认值是50s。    缺点：等待时间太长。 
方法二：发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事 务得以继续执行。将参数innodb_deadlock_detect设置为on，表示开启这个逻辑。

但是如果进程很多，死锁检测耗费大量CPU资源，怎么解决？（1000条进程更新一条数据）

1、确保业务一定不会出现死锁，临时把死锁检测关闭
2、控制并发度，如果在客户端控制，好多客户端打过来 并发数也有很多，所以要做在数据库服务端

如果你有中间件，<mark style="background: #BBFABBA6;">可以考虑在中间件实现</mark>;如果你的 团队有能修改MySQL源码的人，也<mark style="background: #BBFABBA6;">可以做在MySQL里</mark>面。基本思路就是，对于相同行的更新， 在进入引擎之前排队。这样在InnoDB内部就不会有大量的死锁检测工作了。
可能你会问，如果团队里暂时没有数据库方面的专家，不能实现这样的方案，能不能从设 计上优化这个问题呢?
<mark style="background: #BBFABBA6;">你可以考虑通过将一行改成逻辑上的多行来减少锁冲突</mark>。还是以影院账户为例，可以考虑放在多 条记录上，比如10个记录，影院的账户总额等于这10个记录的值的总和。这样每次要给影院账 户加金额的时候，随机选其中一条记录来加。这样每次冲突概率变成原来的1/10，可以减少锁等 待个数，也就减少了死锁检测的CPU消耗。
这个方案看上去是无损的，但其实这类方案需要根据业务逻辑做详细设计。如果账户余额可能会 减少，比如退票逻辑，那么这时候就需要考虑当一部分行记录变成0的时候，代码要有特殊处理。

`START TRANSACTION WITH CONSISTENT SNAPSHOT;` 是 MySQL 中开始事务的一种方式，它会创建一个**一致性快照**（consistent snapshot），确保事务在整个执行过程中看到的是**同一个时间点的数据状态**，不受其他并发事务的影响。

![[1748678468748_d.png]]
事务A查到的是1，事务B查到的是3
在实现上， InnoDB为每个事务构造了一个数组，用来保存这个事务启动瞬间，当前正在“活 跃”的所有事务ID。“活跃”指的就是，启动了但还没提交。
数组里面事务ID的最小值记为低水位，当前系统里面已经创建过的事务ID的最大值加1记为高水 位。
这个视图数组和高水位，就组成了当前事务的一致性视图(read-view)。

这样，对于当前事务的启动瞬间来说，一个数据版本的row trx_id，有以下几种可能:
1. 如果落在绿色部分，表示这个版本是已提交的事务或者是当前事务自己生成的，这个数据是可见的;
2. 如果落在红色部分，表示这个版本是由将来启动的事务生成的，是肯定不可见的;
3. 如果落在黄色部分，那就包括两种情况
a. 若 row trx_id在数组中，表示这个版本是由还没提交的事务生成的，不可见; b. 若 row trx_id不在数组中，表示这个版本是已经提交了的事务生成的，可见。
比如，对于图2中的数据来说，如果有一个事务，它的低水位是18，那么当它访问这一行数据 时，就会从V4通过U3计算出V3，所以在它看来，这一行的值是11。
你看，有了这个声明后，系统里面随后发生的更新，是不是就跟这个事务看到的内容无关了呢? 因为之后的更新，生成的版本一定属于上面的2或者3(a)的情况，而对它来说，这些新的数据版 本是不存在的，所以这个事务的快照，就是“静态”的了。

<mark style="background: #BBFABBA6;">更新数据都是先读后写的，而这个读，只能读当前的 值，称为“当前读”(current read)。</mark>

#### 普通索引和唯一索引
<mark style="background: #BBFABBA6;">对于查询语句，影响微乎其微</mark>（因为查出来那一数据页都放到内存里面了）
对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束。比如，要插入 (4,400)这个记录，就要先判断现在表中是否已经存在k=4的记录，而这必须要将数据页读入内存 才能判断。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用change buffer 了。
因此，唯一索引的更新就不能使用<mark style="background: #BBFABBA6;">change buffer，实际上也只有普通索引可以使用。</mark>
change buffer用的是buffer pool里的内存，因此不能无限增大。change buffer的大小，可以通 过参数innodb_change_buffer_max_size来动态设置。这个参数设置为50的时候，表示change buffer的大小最多只能占用buffer pool的50%。

因此，对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时change buffer的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。
反过来，假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记 录在change buffer，但之后由于马上要访问这个数据页，会立即触发merge过程。这样随机访问 IO的次数不会减少，反而增加了change buffer的维护代价。所以，对于这种业务模式来 说，change buffer反而起到了副作用。

![[1748683804304_d.png]]
redo log 主要节省的是随 机写磁盘的IO消耗(转成顺序写)，而change buffer主要节省的则是随机读磁盘的IO消 耗。

merge的执行流程是这样的:
1. 从磁盘读入数据页到内存(老版本的数据页);
2. 从changebuffer里找出这个数据页的changebuffer记录(可能有多个)，依次应用，得到新 版数据页;
3. 写redolog。这个redolog包含了数据的变更和changebuffer的变更。 到这里merge过程就结束了。这时候，数据页和内存中change buffer对应的磁盘位置都还没有修
改，属于脏页，之后各自刷回自己的物理数据，就是另外一个过程了。

#### 给字符串字段 加索引
<mark style="background: #FFB8EBA6;">mysql> alter table SUser add index index2(email(6));</mark>
![[1748687013951_d.png]]
使用前缀可能会增加扫描行数
![[Pasted image 20250531183037.png]]
前缀大部分相同，怎么办
1、使用倒序查询
2、使用hash字段
![[1748687978259_d.png]]

#### 表数据删除一半，表文件大小不变
进一步地，如果我们用delete命令把整个表的数据删除呢?结果就是，所有的数据页都会被标记 为可复用。但是磁盘上，文件不会变小。
你现在知道了，delete命令其实只是把记录的位置，或者数据页标记为了“可复用”，但磁盘文件 的大小是不会变的。也就是说，通过delete命令是不能回收表空间的。这些可以复用，而没有被 使用的空间，看起来就像是“空洞”。
- **收缩**：默认情况下**不会自动收缩**文件大小，因为：
    - 收缩操作代价高(需要重建表)
    - 这些空间很可能被后续插入复用
    - 频繁调整文件大小影响性能
<mark style="background: #BBFABBA6;">为了去掉空洞，可以用重建表</mark>
![[1748767753657_d.png]]
DDL之前是要拿MDL写锁的，这样还能叫Online DDL吗? 确实，图4的流程中，alter语句在启动的时候需要获取MDL写锁，但是这个写锁在真正拷贝数据
之前就退化成读锁了。 为什么要退化呢?为了实现Online，MDL读锁不会阻塞增删改操作。 那为什么不干脆直接解锁呢?为了保护自己，禁止其他线程对这个表同时做DDL。
而对于一个大表来说，Online DDL最耗时的过程就是拷贝数据到临时表的过程，这个步骤的执 行期间可以接受增删改操作。所以，相对于整个DDL过程来说，锁的时间非常短。对业务来说， 就可以认为是Online的。

在图4中，根据表A重建出来的数据是放在“tmp_file”里的，这个临时文件是InnoDB在内部创建出 来的。整个DDL过程都在InnoDB内部完成。对于server层来说，没有把数据挪动到临时表，是 一个“原地”操作，这就是“inplace”名称的来源。
所以，我现在问你，如果你有一个1TB的表，现在磁盘间是1.2TB，能不能做一个inplace的DDL 呢?
答案是不能。因为，tmp_file也是要占用临时空间的。

inplace和Online在重建表中是一个意思
![[1748768503720_d.png]]

注意，这个操作很消耗IO和CPU资源，
```sql
alter table t engine=innodb -- 重建表 默认ALGORITHM=inplace
```
#### count(* )很慢
![[1748769291622_d.png]]

要把数据一条一条拿出来计数

办法，把计数值放到MySQL里面，单独开一个事务，不要放Redis里面，会导致数据不一致。

![[1748770475285_d.png]]

#### 排序
```sql
select city,name,age from t where city='杭州' order by name limit 1000 ;
```

首先，为了避免全表检索，设置city的索引

##### 全字段排序
过程如下：
1. 划出buffer缓存区，确定放入city,name,age三个字段
2. 从索引city里面找出主键id
3. 根据Id回表，把city,name,age三个字段值存到buffer里面
4. 从索引city里面取下一个id
5. 重复3,4
6. 对buffer里面数据按照name字段做快速排序
7. 取前一千行返回客户端

图中“按name排序”这个动作，可能在内存中完成，也可能需要使用外部排序，这取决于排序所
需的内存和参数sort_buffer_size。
sort_buffer_size，就是MySQL为排序开辟的内存(sort_buffer)的大小。如果要排序的数据量 小于sort_buffer_size，排序就在内存中完成。但如果排序数据量太大，内存放不下，则不得不 利用磁盘临时文件辅助排序。
MySQL将需要排序的数据分成12份，每一份单独排序后存在这些临时文件中。然后把 这12个有序文件再合并成一个有序的大文件。
如果sort_buffer_size超过了需要排序的数据量的大小，number_of_tmp_files就是0，表示排序 可以直接在内存中完成。

SET max_length_for_sort_data = 16;
##### rowid排序
city、name、age 这三个字段的定义总长度是36，我把max_length_for_sort_data设置为16，我 们再来看看计算过程有什么改变。
新的算法放入sort_buffer的字段，只有要排序的列(即name字段)和主键id。 但这时，排序的结果就因为少了city和age字段的值，不能直接返回了，整个执行流程就变成如
下所示的样子:
1. 初始化sort_buffer，确定放入两个字段，即name和id;
2. 从索引city找到第一个满足city='杭州’条件的主键id，也就是图中的ID_X;
3. 到主键id索引取出整行，取name、id这两个字段，存入sort_buffer中;
4. 从索引city取下一个记录的主键id;
5. 重复步骤3、4直到不满足city='杭州’条件为止，也就是图中的ID_Y;
6. 对sort_buffer中的数据按照字段name进行排序;
7. 遍历排序结果，取前1000行，并按照id的值回到原表中取出city、name和age三个字段返回 给客户端。


对（city,name）创建联合索引，就不用单独排序了，
1. 从索引(city,name)找到第一个满足city='杭州’条件的主键id;
2. 到主键id索引取出整行，取name、city、age三个字段的值，作为结果集的一部分直接返 回;
3. 从索引(city,name)取下一个记录主键id;
4. 重复步骤2、3，直到查到第1000条记录，或者是不满足city='杭州’条件时循环结束。
只需要扫描1000次

或者直接创建（city,name,age）联合索引，更省事不用回表了